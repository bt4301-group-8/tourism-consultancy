{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data from file\n",
    "with open('country_posts.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>play_count</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üïåüíñ\\n‡øì \\n*\\n*\\n#BandarSeriBegawan #Brunei #ÊñáËé± #Ê±∂Ëêä</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-09-26 00:25:42+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>brunei</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bandar Seri Begawan, the capital of the tiny o...</td>\n",
       "      <td>182</td>\n",
       "      <td>2025-01-05 21:20:35+00:00</td>\n",
       "      <td>3569</td>\n",
       "      <td>0</td>\n",
       "      <td>brunei</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jerudong Park, Brunei, new year's eve 1996.\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-08 04:37:02+00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>brunei</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First time seeing a Unimog and it was quite th...</td>\n",
       "      <td>45</td>\n",
       "      <td>2023-08-24 16:36:23+00:00</td>\n",
       "      <td>635</td>\n",
       "      <td>0</td>\n",
       "      <td>brunei</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flowers are always the way to a woman‚Äôs heart!...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-14 05:27:27+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>217</td>\n",
       "      <td>brunei</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>TOP16 IN POPPING HAND STYLE üî´\\n AT @radikalfor...</td>\n",
       "      <td>212</td>\n",
       "      <td>2024-01-11 07:08:13+00:00</td>\n",
       "      <td>1999</td>\n",
       "      <td>22522</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>–°–ª—É—à–∞—Ç—å –∏ –Ω–∞—Å–ª–∞–∂–¥–∞—Ç—å—Å—è ‚ù§Ô∏è\\n\\n#–Ω—è—á–∞–Ω–≥–≤—å–µ—Ç–Ω–∞–º #—é...</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-03-08 22:05:23+00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>–ù—É –∫–∞–∫ –≤–∞–º —Ñ–æ—Ç–æ, –∫–æ—Ç–æ—Ä—ã–µ —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞ —Å–¥–µ–ª–∞–ª...</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-08-22 20:16:46+00:00</td>\n",
       "      <td>722</td>\n",
       "      <td>0</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6674</th>\n",
       "      <td>‚ú®MoonDog‚ú®\\n\\nAmazing restaurant with the best ...</td>\n",
       "      <td>25</td>\n",
       "      <td>2022-02-28 16:17:40+00:00</td>\n",
       "      <td>3280</td>\n",
       "      <td>68071</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6675</th>\n",
       "      <td>Âú∞‰∏ã„ÅÆÁßòÂØÜÂ£ï„Åã„ÇâÊºÇ„ÅÜÈÅéÂéª„ÅÆÈ¶ô„Çä„ÄÅÊúüÈñìÈôêÂÆö„ÅÆÁâπÂà•Â±ïÁ§∫„ÇÇ~ üáªüá≥\\n\\n‡∏Ö^‚Ä¢Ôªå‚Ä¢^‡∏Ö\\n\\n‚†Ä...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-27 22:20:38+00:00</td>\n",
       "      <td>3460</td>\n",
       "      <td>0</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6676 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                caption  comment_count  \\\n",
       "0      üïåüíñ\\n‡øì \\n*\\n*\\n#BandarSeriBegawan #Brunei #ÊñáËé± #Ê±∂Ëêä             12   \n",
       "1     Bandar Seri Begawan, the capital of the tiny o...            182   \n",
       "2     Jerudong Park, Brunei, new year's eve 1996.\\n\\...              1   \n",
       "3     First time seeing a Unimog and it was quite th...             45   \n",
       "4     Flowers are always the way to a woman‚Äôs heart!...              0   \n",
       "...                                                 ...            ...   \n",
       "6671  TOP16 IN POPPING HAND STYLE üî´\\n AT @radikalfor...            212   \n",
       "6672  –°–ª—É—à–∞—Ç—å –∏ –Ω–∞—Å–ª–∞–∂–¥–∞—Ç—å—Å—è ‚ù§Ô∏è\\n\\n#–Ω—è—á–∞–Ω–≥–≤—å–µ—Ç–Ω–∞–º #—é...              6   \n",
       "6673  –ù—É –∫–∞–∫ –≤–∞–º —Ñ–æ—Ç–æ, –∫–æ—Ç–æ—Ä—ã–µ —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞ —Å–¥–µ–ª–∞–ª...             25   \n",
       "6674  ‚ú®MoonDog‚ú®\\n\\nAmazing restaurant with the best ...             25   \n",
       "6675  Âú∞‰∏ã„ÅÆÁßòÂØÜÂ£ï„Åã„ÇâÊºÇ„ÅÜÈÅéÂéª„ÅÆÈ¶ô„Çä„ÄÅÊúüÈñìÈôêÂÆö„ÅÆÁâπÂà•Â±ïÁ§∫„ÇÇ~ üáªüá≥\\n\\n‡∏Ö^‚Ä¢Ôªå‚Ä¢^‡∏Ö\\n\\n‚†Ä...              1   \n",
       "\n",
       "                           date  like_count  play_count  country location  \n",
       "0     2023-09-26 00:25:42+00:00           3           0   brunei      NaN  \n",
       "1     2025-01-05 21:20:35+00:00        3569           0   brunei      NaN  \n",
       "2     2024-08-08 04:37:02+00:00         103           0   brunei      NaN  \n",
       "3     2023-08-24 16:36:23+00:00         635           0   brunei      NaN  \n",
       "4     2024-05-14 05:27:27+00:00           3         217   brunei      NaN  \n",
       "...                         ...         ...         ...      ...      ...  \n",
       "6671  2024-01-11 07:08:13+00:00        1999       22522  vietnam      NaN  \n",
       "6672  2024-03-08 22:05:23+00:00         290           0  vietnam      NaN  \n",
       "6673  2023-08-22 20:16:46+00:00         722           0  vietnam      NaN  \n",
       "6674  2022-02-28 16:17:40+00:00        3280       68071  vietnam      NaN  \n",
       "6675  2022-08-27 22:20:38+00:00        3460           0  vietnam      NaN  \n",
       "\n",
       "[6676 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each country (key) and normalize the data\n",
    "for country, posts in data.items():\n",
    "    # Normalize the data\n",
    "    df = pd.json_normalize(posts)\n",
    "    \n",
    "    # Add a column for the country (this will help you identify the source)\n",
    "    df['country'] = country\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          date   date_only time_only\n",
      "0    2023-09-26 00:25:42+00:00  2023-09-26  00:25:42\n",
      "1    2025-01-05 21:20:35+00:00  2025-01-05  21:20:35\n",
      "2    2024-08-08 04:37:02+00:00  2024-08-08  04:37:02\n",
      "3    2023-08-24 16:36:23+00:00  2023-08-24  16:36:23\n",
      "4    2024-05-14 05:27:27+00:00  2024-05-14  05:27:27\n",
      "...                        ...         ...       ...\n",
      "6671 2024-01-11 07:08:13+00:00  2024-01-11  07:08:13\n",
      "6672 2024-03-08 22:05:23+00:00  2024-03-08  22:05:23\n",
      "6673 2023-08-22 20:16:46+00:00  2023-08-22  20:16:46\n",
      "6674 2022-02-28 16:17:40+00:00  2022-02-28  16:17:40\n",
      "6675 2022-08-27 22:20:38+00:00  2022-08-27  22:20:38\n",
      "\n",
      "[6676 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "final_df['date'] = pd.to_datetime(final_df['date'])\n",
    "\n",
    "# Split into separate 'date' and 'time' columns\n",
    "final_df['date_only'] = final_df['date'].dt.date\n",
    "final_df['time_only'] = final_df['date'].dt.time\n",
    "\n",
    "# Display the updated DataFrame with new columns\n",
    "print(final_df[['date', 'date_only', 'time_only']])\n",
    "\n",
    "# # Extract day of the week (0 = Monday, 6 = Sunday)\n",
    "# final_df['day_of_week'] = final_df['date'].dt.dayofweek\n",
    "\n",
    "# # Extract month\n",
    "# final_df['month'] = final_df['date'].dt.month\n",
    "\n",
    "# # Extract year\n",
    "# final_df['year'] = final_df['date'].dt.year\n",
    "\n",
    "# # Extract whether the post was made on a weekend (1 if weekend, 0 if weekday)\n",
    "# final_df['is_weekend'] = final_df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# # Optionally, extract the weekday name (e.g., Monday, Tuesday)\n",
    "# final_df['weekday_name'] = final_df['date'].dt.strftime('%A')\n",
    "\n",
    "# # Display the updated DataFrame with new columns\n",
    "# print(final_df[['date', 'date_only', 'time_only', 'day_of_week', 'month', 'year', 'is_weekend', 'weekday_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                caption  \\\n",
      "0      üïåüíñ\\n‡øì \\n*\\n*\\n#BandarSeriBegawan #Brunei #ÊñáËé± #Ê±∂Ëêä   \n",
      "1     Bandar Seri Begawan, the capital of the tiny o...   \n",
      "2     Jerudong Park, Brunei, new year's eve 1996.\\n\\...   \n",
      "3     First time seeing a Unimog and it was quite th...   \n",
      "4     Flowers are always the way to a woman‚Äôs heart!...   \n",
      "...                                                 ...   \n",
      "6671  TOP16 IN POPPING HAND STYLE üî´\\n AT @radikalfor...   \n",
      "6672  –°–ª—É—à–∞—Ç—å –∏ –Ω–∞—Å–ª–∞–∂–¥–∞—Ç—å—Å—è ‚ù§Ô∏è\\n\\n#–Ω—è—á–∞–Ω–≥–≤—å–µ—Ç–Ω–∞–º #—é...   \n",
      "6673  –ù—É –∫–∞–∫ –≤–∞–º —Ñ–æ—Ç–æ, –∫–æ—Ç–æ—Ä—ã–µ —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞ —Å–¥–µ–ª–∞–ª...   \n",
      "6674  ‚ú®MoonDog‚ú®\\n\\nAmazing restaurant with the best ...   \n",
      "6675  Âú∞‰∏ã„ÅÆÁßòÂØÜÂ£ï„Åã„ÇâÊºÇ„ÅÜÈÅéÂéª„ÅÆÈ¶ô„Çä„ÄÅÊúüÈñìÈôêÂÆö„ÅÆÁâπÂà•Â±ïÁ§∫„ÇÇ~ üáªüá≥\\n\\n‡∏Ö^‚Ä¢Ôªå‚Ä¢^‡∏Ö\\n\\n‚†Ä...   \n",
      "\n",
      "                                        cleaned_caption  \n",
      "0                        BandarSeriBegawan Brunei ÊñáËé± Ê±∂Ëêä  \n",
      "1     Bandar Seri Begawan, the capital of the tiny o...  \n",
      "2     Jerudong Park, Brunei, new years eve 1996. Mic...  \n",
      "3     First time seeing a Unimog and it was quite th...  \n",
      "4     Flowers are always the way to a womans heart! ...  \n",
      "...                                                 ...  \n",
      "6671  TOP16 IN POPPING HAND STYLE AT radikalforzejam...  \n",
      "6672  –°–ª—É—à–∞—Ç—å –∏ –Ω–∞—Å–ª–∞–∂–¥–∞—Ç—å—Å—è –Ω—è—á–∞–Ω–≥–≤—å–µ—Ç–Ω–∞–º —é–∂–Ω–æ–∫–∏—Ç–∞–π...  \n",
      "6673  –ù—É –∫–∞–∫ –≤–∞–º —Ñ–æ—Ç–æ, –∫–æ—Ç–æ—Ä—ã–µ —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞ —Å–¥–µ–ª–∞–ª...  \n",
      "6674  MoonDog Amazing restaurant with the best vibes...  \n",
      "6675  Âú∞‰∏ã„ÅÆÁßòÂØÜÂ£ï„Åã„ÇâÊºÇ„ÅÜÈÅéÂéª„ÅÆÈ¶ô„ÇäÊúüÈñìÈôêÂÆö„ÅÆÁâπÂà•Â±ïÁ§∫„ÇÇ ‡∏ÖÔªå‡∏Ö dogs dogsofinsta...  \n",
      "\n",
      "[6676 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Remove emojis and other unwanted symbols\n",
    "    text = re.sub(r'[^\\w\\s,.!?;]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove extra spaces and trim\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "final_df['cleaned_caption'] = final_df['caption'].apply(clean_text)\n",
    "\n",
    "# Display cleaned captions\n",
    "print(final_df[['caption', 'cleaned_caption']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def analyze_and_translate_languages_with_google(dataset):\n",
    "    # Initialize the Google Translator\n",
    "    translator = Translator()\n",
    "\n",
    "    # Function to detect language using Google Translator\n",
    "    def detect_language(text):\n",
    "        try:\n",
    "            return translator.detect(text).lang\n",
    "        except Exception as e:\n",
    "            return 'unknown'\n",
    "\n",
    "    # Function to translate text to English\n",
    "    def translate_to_english(text):\n",
    "        try:\n",
    "            return translator.translate(text, dest='en').text\n",
    "        except Exception as e:\n",
    "            return None\n",
    "\n",
    "    # List to keep track of rows to drop\n",
    "    to_drop = []\n",
    "\n",
    "    # Iterate over the dataset and apply the logic for detecting and translating languages\n",
    "    for index, row in dataset.iterrows():\n",
    "        detected_language = detect_language(row[\"cleaned_caption\"])\n",
    "\n",
    "        if detected_language == 'en':\n",
    "            dataset.at[index, \"language\"] = 'en'\n",
    "            continue  # If already English, move to the next caption\n",
    "        elif detected_language == 'unknown':\n",
    "            to_drop.append(index)  # Drop the row if language is unknown\n",
    "        else:\n",
    "            # Translate to English\n",
    "            translated_text = translate_to_english(row[\"cleaned_caption\"])\n",
    "            if translated_text:\n",
    "                # Re-detect language after translation\n",
    "                new_language = detect_language(translated_text)\n",
    "                if new_language == 'en':\n",
    "                    # Update with the translated text and mark the language as English\n",
    "                    dataset.at[index, \"cleaned_caption\"] = translated_text\n",
    "                    dataset.at[index, \"language\"] = 'en'\n",
    "                else:\n",
    "                    to_drop.append(index)  # Drop if still not English\n",
    "            else:\n",
    "                to_drop.append(index)  # Drop if translation failed\n",
    "\n",
    "    # Drop rows where the language is still unknown or non-English\n",
    "    dataset.drop(to_drop, inplace=True)\n",
    "\n",
    "    return dataset  # Return the cleaned dataset with only English caption\n",
    "\n",
    "# Example usage with your dataset\n",
    "translated_caption = analyze_and_translate_languages_with_google(final_df)\n",
    "print(translated_caption[['cleaned_caption', 'language']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             caption  comment_count  \\\n",
      "1  Just wrapped up an epic core & full-body sessi...             22   \n",
      "2  –°–ª—É—á–∞–π–Ω—ã–µ –∫–∞–¥—Ä—ã —Å –ë–∞–ª–∏ üåø –ö–∞–∫–æ–π –∫–∞–¥—Ä –Ω—Ä–∞–≤–∏—Ç—Å—è –±...             30   \n",
      "3  „Åì„ÅìÊï∞Âπ¥„Åß„Éê„É™Â≥∂„Åß„ÅØ„Éà„É™„É•„Éï„ÉÅ„Éß„Ç≥„ÇíÊâ±„ÅÜ„ÉÅ„Éß„Ç≥„É¨„Éº„ÉàÂ∞ÇÈñÄÂ∫ó„ÅåÂ¢ó„Åà„Åæ„Åó„Åü„Åå„ÄÅ„Åì„Å°„Çâ„ÇÇ„Åù„ÅÆ‰∏Ä„Å§ÔºÅ...              2   \n",
      "4  Nggak heran lagi deh sama Hyoyeon kalo tiba-ti...             26   \n",
      "5  üìçCretya Ubud, Bali üáÆüá©\\n.\\n.\\n.\\n#cretyaubud #c...             65   \n",
      "\n",
      "                       date  like_count  play_count country location  \\\n",
      "1 2025-01-07 17:58:32+00:00        1259           0    bali      NaN   \n",
      "2 2022-08-04 03:04:51+00:00         559           0    bali      NaN   \n",
      "3 2023-04-29 20:40:00+00:00         559           0    bali      NaN   \n",
      "4 2023-10-18 01:46:08+00:00        1985      120120    bali      NaN   \n",
      "5 2024-12-07 11:59:29+00:00         936           0    bali      NaN   \n",
      "\n",
      "    date_only time_only  day_of_week  month  year  is_weekend weekday_name  \\\n",
      "1  2025-01-07  17:58:32            1      1  2025           0      Tuesday   \n",
      "2  2022-08-04  03:04:51            3      8  2022           0     Thursday   \n",
      "3  2023-04-29  20:40:00            5      4  2023           1     Saturday   \n",
      "4  2023-10-18  01:46:08            2     10  2023           0    Wednesday   \n",
      "5  2024-12-07  11:59:29            5     12  2024           1     Saturday   \n",
      "\n",
      "                                     cleaned_caption language  sentiment_score  \n",
      "1  Just Wrapped Up An Epic Core Fullbody Session ...       en           0.8302  \n",
      "2  Random shots with Bali What frame do you like ...       en           0.3612  \n",
      "3  Over the past few years, there have been an in...       en           0.9847  \n",
      "4  No wonder again with Hyoyeon if suddenly in Ba...       en           0.5189  \n",
      "5  Cretya Ubud, Bali . . . cretyaubud cretya cret...       en           0.0000  \n"
     ]
    }
   ],
   "source": [
    "# do sentiment analysis and give sentiment scores using vader nlp\n",
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply sentiment analysis\n",
    "translated_caption[\"sentiment_score\"] = translated_caption[\"cleaned_caption\"].apply(lambda text: analyzer.polarity_scores(text)[\"compound\"])\n",
    "\n",
    "# Display the results\n",
    "print(translated_caption.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_caption.to_json(\"sentiment_analysis(instagram).json\", orient=\"records\", date_format=\"iso\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
